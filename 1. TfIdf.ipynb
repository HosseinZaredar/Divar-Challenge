{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f0928c",
   "metadata": {},
   "source": [
    "### Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7c82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afe1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('DMC-Train.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665b96b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_data</th>\n",
       "      <th>review_label</th>\n",
       "      <th>reject_reason_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb000599-2ee2-42c1-9f0e-32cfeb940398</td>\n",
       "      <td>{\"body_status\": \"witout-color\", \"brand\": \"\\u06...</td>\n",
       "      <td>accept</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12063741-6634-444b-befa-0be4c95c2b42</td>\n",
       "      <td>{\"body_status\": \"witout-color\", \"brand\": \"\\u06...</td>\n",
       "      <td>reject</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81c93119-5c06-412f-80aa-363ddb0ebc33</td>\n",
       "      <td>{\"body_status\": \"witout-color\", \"brand\": \"\\u06...</td>\n",
       "      <td>accept</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5a5bfa7-03be-408b-b4d9-bca26c0ca59b</td>\n",
       "      <td>{\"brand\": \"\\u0633\\u0627\\u06cc\\u0631\", \"brand_m...</td>\n",
       "      <td>accept</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3414e920-dfaf-44a8-9853-0b03d66e9e2a</td>\n",
       "      <td>{\"body_status\": \"intact\", \"brand\": \"\\u067e\\u06...</td>\n",
       "      <td>reject</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                post_id  \\\n",
       "0  cb000599-2ee2-42c1-9f0e-32cfeb940398   \n",
       "1  12063741-6634-444b-befa-0be4c95c2b42   \n",
       "2  81c93119-5c06-412f-80aa-363ddb0ebc33   \n",
       "3  b5a5bfa7-03be-408b-b4d9-bca26c0ca59b   \n",
       "4  3414e920-dfaf-44a8-9853-0b03d66e9e2a   \n",
       "\n",
       "                                           post_data review_label  \\\n",
       "0  {\"body_status\": \"witout-color\", \"brand\": \"\\u06...       accept   \n",
       "1  {\"body_status\": \"witout-color\", \"brand\": \"\\u06...       reject   \n",
       "2  {\"body_status\": \"witout-color\", \"brand\": \"\\u06...       accept   \n",
       "3  {\"brand\": \"\\u0633\\u0627\\u06cc\\u0631\", \"brand_m...       accept   \n",
       "4  {\"body_status\": \"intact\", \"brand\": \"\\u067e\\u06...       reject   \n",
       "\n",
       "   reject_reason_id  \n",
       "0                 0  \n",
       "1                13  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc3d5b",
   "metadata": {},
   "source": [
    "### Unwrap JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b29f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4731b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_json(dataframe):\n",
    "    post_df = pd.json_normalize(dataframe.post_data.apply(json.loads))\n",
    "    post_df = post_df.drop(post_df.columns[15:], axis=1) # removing optional columns\n",
    "    dataframe = pd.concat([post_df, dataframe], axis=1)\n",
    "    dataframe = dataframe.drop('post_data', axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2641b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = unwrap_json(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68f092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_label'] = train_df['review_label'].map({'accept': 1, 'reject': 0})\n",
    "train_label = train_df[['review_label']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a403e",
   "metadata": {},
   "source": [
    "### Analyzing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "profile.to_file(\"dataset_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa4168",
   "metadata": {},
   "source": [
    "#### Fields\n",
    "\n",
    "- body_status: pre-defined (16 types) - 20% missing\n",
    "- brand: pre-defined (with other) (30 types) - 0.1% missing\n",
    "- brand_model: pre-defined (with other) (1135 types) - 0.2% missing\n",
    "- color: pre-defined (38 types) - 3% missing\n",
    "- description: free text - 0% missing\n",
    "- document: pre-defined (3 types) - 21% missing\n",
    "- gearbox: pre-defined (2 types) - 20% missing\n",
    "- new_price: 10M - 50B integer - 25% missing\n",
    "- selling_type: pre-defined (3 types) - 22% missing\n",
    "- third_party_insurance_deadline: 1-12 integer - 22% missing\n",
    "- title: free text (with suggestion) - 0% missing\n",
    "- usage: 0-500,000 km integer - 0.1% missing\n",
    "- year: pre-defined (36 types) - 0.1% missing\n",
    "- options: yes or no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762b183",
   "metadata": {},
   "source": [
    "#### Reasons\n",
    "\n",
    "- 0: cool = 77.1% (inbalanced data)\n",
    "- 12: against the law = 5.0%\n",
    "- 145: you cannot request to buy, you only sell! = 4.8%\n",
    "- 163: info doesn't match the title = 4.2%\n",
    "- 13: probably wrong price = 3.9%\n",
    "- 139: more than one car = 3.9%\n",
    "- 146: wrong category = 0.5%\n",
    "- 5: wrong category, use services = 0.3%\n",
    "- 29: no document uploaded (actually, not related to document field, nor any other field!) = 0.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "df.loc[df['reject_reason_id'] == 145].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f962251",
   "metadata": {},
   "source": [
    "### Categorical to One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c427541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03811ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_onehot(dataframe):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(dataframe)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b310ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clm in opt_columns:\n",
    "    train_df[clm] = train_df[clm].map({np.nan: 'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b047bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['body_status', 'brand', 'brand_model', 'color', 'document', 'gearbox',\n",
    "               'selling_type', 'year', 'third_party_insurance_deadline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c3bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_model = train_onehot(train_df[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad851fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = onehot_model.transform(train_df[cat_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec1732",
   "metadata": {},
   "source": [
    "### Numerical to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f24781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc949bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_num2cat(dataframe, num_bins):\n",
    "    bins = pd.qcut(dataframe, duplicates='drop', q=num_bins, retbins=True)[1]\n",
    "    bins = np.concatenate(([-np.inf], bins[1:-1], [np.inf]))\n",
    "    res_df = pd.cut(dataframe, bins).to_frame()\n",
    "    oh_model = train_onehot(res_df)\n",
    "    return bins, oh_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6317006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_num2cat(dataframe, model, bins):\n",
    "    res_df = pd.cut(dataframe, bins).to_frame()\n",
    "    return model.transform(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2af344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bins, price_model = train_num2cat(train_df['new_price'], 50)\n",
    "train_price = transform_num2cat(train_df['new_price'], price_model, price_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6f6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_bins, usage_model = train_num2cat(train_df['usage'], 25)\n",
    "train_usage = transform_num2cat(train_df['usage'], usage_model, usage_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c2a19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = hstack((train_cat, train_price, train_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15208a",
   "metadata": {},
   "source": [
    "### Cleaning Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "663dd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hazm\n",
    "from hazm import Normalizer, WordTokenizer\n",
    "import re\n",
    "import pickle\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a320c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_translation_dict.pickle', 'rb') as handle:\n",
    "    new_translation = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cad6a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.dat') as handle:\n",
    "    stopwords = handle.readlines()\n",
    "    stopwords = [word[:-1] for word in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "490ba89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextHandler:\n",
    "    def __init__(self, persian_numbers=False,\n",
    "                 change_lang_spacing=True,\n",
    "                 remove_non_standard_char=True,\n",
    "                 remove_repetitive_chars=True,\n",
    "                 user_translations=None,\n",
    "                 stopwords=None,\n",
    "                 lemma=False\n",
    "                ):\n",
    "        \n",
    "        if not persian_numbers:\n",
    "            number_src = '۰۱۲۳۴۵۶۷۸۹٪'\n",
    "            number_dest = '0123456789%'\n",
    "        else:\n",
    "            number_dest = '۰۱۲۳۴۵۶۷۸۹٪'\n",
    "            number_src = '0123456789%'\n",
    "        \n",
    "        self.number_translations = self.maketrans(number_src, number_dest)\n",
    "        \n",
    "        if not user_translations:\n",
    "            self.user_translations = dict()\n",
    "        else:\n",
    "            self.user_translations = user_translations\n",
    "\n",
    "        self._remove_repetitive_chars = remove_repetitive_chars\n",
    "        self._change_lang_spacing = change_lang_spacing\n",
    "        self._remove_non_standard_char = remove_non_standard_char\n",
    "        self._stopwords = stopwords\n",
    "        \n",
    "        self.text_normalizer = hazm.Normalizer(\n",
    "            remove_extra_spaces=True,\n",
    "            persian_style=False,\n",
    "            persian_numbers=False,\n",
    "            remove_diacritics=True,\n",
    "            affix_spacing=True,\n",
    "            token_based=False,\n",
    "            punctuation_spacing=True)\n",
    "\n",
    "        self.word_tokenizer = hazm.WordTokenizer(\n",
    "            join_verb_parts=False,\n",
    "            separate_emoji=True,\n",
    "            replace_links=True,\n",
    "            replace_IDs=False,\n",
    "            replace_emails=True,\n",
    "            replace_numbers=False,\n",
    "            replace_hashtags=False)\n",
    "\n",
    "    def normalize(self, text: str):\n",
    "        text = text.translate(self.user_translations)\n",
    "        text = text.translate(self.number_translations)\n",
    "        \n",
    "        text = text.lower()\n",
    "\n",
    "        normalized_text = self.text_normalizer.normalize(text)\n",
    "\n",
    "        if self._remove_repetitive_chars:\n",
    "            text = self.remove_rep_chars(text)\n",
    "\n",
    "        if self._change_lang_spacing:\n",
    "            text = self.change_lang_spacing(text)\n",
    "\n",
    "        if self._remove_non_standard_char:\n",
    "            text = self.remove_non_standard_char(text)\n",
    "            \n",
    "        text = self.remove_stopwords(text)\n",
    "\n",
    "        text = re.sub(r'[\\u200c\\s]*\\s[\\s\\u200c]*', ' ', text)\n",
    "        text = re.sub(r'[\\u200c]+', '\\u200c', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def maketrans(src_chars, dest_chars):\n",
    "        return dict((ord(a), b) for a, b in zip(src_chars, dest_chars))\n",
    "    \n",
    "    @staticmethod\n",
    "    def change_lang_spacing(text: str) -> str:\n",
    "        return re.sub('(([a-zA-Z0-9/\\-\\.]+)|([ء-یژپچگ]+))', r' \\1 ', text).strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_non_standard_char(text: str) -> str:\n",
    "        return re.sub(r'[^a-zA-Z0-9\\u0621-\\u06CC\\u0698\\u067E\\u0686\\u06AF]', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_rep_chars(text: str) -> str:\n",
    "        return re.sub(r'([^0-9])\\1\\1+', r'\\1', text)\n",
    "    \n",
    "    def remove_stopwords_and_lemma(self, text: str) -> str:\n",
    "        if self._stopwords:\n",
    "            words = self.word_tokenizer.tokenize(text)\n",
    "            words = [w for w in words if w not in self._stopwords]\n",
    "            return ' '.join(words)\n",
    "        return text\n",
    "    \n",
    "    def preprocess_text(self, text: str):\n",
    "        normalized_text = self.normalize(text)\n",
    "        return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c8f0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_handler = TextHandler(user_translations=new_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bca34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prep_title'] = train_df['title'].apply(text_handler.preprocess_text)\n",
    "train_df['prep_description'] = train_df['description'].apply(text_handler.preprocess_text)\n",
    "train_df['prep_text'] = train_df['prep_title'] + ' ' + train_df['prep_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8634c9",
   "metadata": {},
   "source": [
    "### Text to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f74b3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af6ac638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_text2vec(dataframe, min_df=20):\n",
    "    tokenizer = hazm.WordTokenizer(\n",
    "        join_verb_parts=False,\n",
    "        separate_emoji=True,\n",
    "        replace_links=True,\n",
    "        replace_IDs=False,\n",
    "        replace_emails=True,\n",
    "        replace_numbers=False,\n",
    "        replace_hashtags=False\n",
    "    )\n",
    "    vect_tf_idf = TfidfVectorizer(sublinear_tf=True, tokenizer=tokenizer.tokenize, min_df=min_df, max_df=0.75)\n",
    "    vect_tf_idf.fit(dataframe.prep_text)\n",
    "    return vect_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d55b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hossein/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t2v_model = train_text2vec(train_df, min_df=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bc6ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = t2v_model.transform(train_df.iloc[:]['prep_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f297bd",
   "metadata": {},
   "source": [
    "### Creating Training Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c4ba02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6fa84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = csr_matrix(train_cat)\n",
    "train_mat = hstack((train_cat, train_text))\n",
    "train_mat = csr_matrix(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c508d77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540362, 13862)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d614f",
   "metadata": {},
   "source": [
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0599ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a68b43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(hstack((train_mat, train_label)), test_size=0.1)\n",
    "X_train = train[:, :-1]\n",
    "X_val = val[:, :-1]\n",
    "y_train = train[:, -1].toarray().squeeze()\n",
    "y_val = val[:, -1].toarray().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274d06a",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19b5d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ddefa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb7acfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_val, y_val):\n",
    "    return (model.score(X_train, y_train),\n",
    "            model.score(X_val, y_val),\n",
    "            roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]),\n",
    "            roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77cf6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X_train, y_train, X_val, y_val, max_iter):\n",
    "    clf = MLPClassifier(random_state=0, hidden_layer_sizes=(400, 50, 10), learning_rate_init=0.001,\n",
    "                   activation='relu', alpha=0.001, max_iter=1, warm_start=True, verbose=True)\n",
    "    prev_clf = deepcopy(clf)\n",
    "    prev_val_acc = 0\n",
    "    prev_val_auc = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_acc, val_acc, train_auc, val_auc = evaluate(clf, X_train, y_train, X_val, y_val)\n",
    "        print(f'train acc= {train_acc:.4f}, val acc= {val_acc:.4f}',\n",
    "              f'train auc= {train_auc:.4f}, val auc= {val_auc:.4f}')\n",
    "        print()\n",
    "        \n",
    "        if val_acc < prev_val_acc or val_auc < prev_val_auc:\n",
    "            clf = prev_clf\n",
    "            print(f'Falling back to Iteration {i}')\n",
    "            break\n",
    "        \n",
    "        prev_val_acc = val_acc\n",
    "        prev_val_auc = val_auc\n",
    "        prev_clf = deepcopy(clf)\n",
    "            \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db92227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.24058205\n",
      "train acc= 0.9417, val acc= 0.9283 train auc= 0.9686, val auc= 0.9552\n",
      "\n",
      "Iteration 2, loss = 0.19413514\n",
      "train acc= 0.9546, val acc= 0.9322 train auc= 0.9795, val auc= 0.9589\n",
      "\n",
      "Iteration 3, loss = 0.17186610\n",
      "train acc= 0.9613, val acc= 0.9316 train auc= 0.9853, val auc= 0.9578\n",
      "\n",
      "Falling back to Iteration 2\n"
     ]
    }
   ],
   "source": [
    "clf = train_mlp(X_train, y_train, X_val, y_val, max_iter=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d535e7",
   "metadata": {},
   "source": [
    "### Loading & Preprocessing Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "76208583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('DMC-phase2-validation.parquet', engine='fastparquet')\n",
    "test_df = unwrap_json(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d70b3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = onehot_model.transform(test_df[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "05538254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107241, 1283)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0c2f2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_price = transform_num2cat(test_df['new_price'], price_model, price_bins)\n",
    "test_usage = transform_num2cat(test_df['usage'], usage_model, usage_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d5e197b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = hstack((test_cat, test_price, test_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "07ee48c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107241, 1425)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "76de1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prep_title'] = test_df['title'].apply(text_handler.preprocess_text)\n",
    "test_df['prep_description'] = test_df['description'].apply(text_handler.preprocess_text)\n",
    "test_df['prep_text'] = test_df['prep_title'] + \" \" + test_df['prep_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = t2v_model.transform(test_df.iloc[:]['prep_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "adb0833d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107241, 21660)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "11f8ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = csr_matrix(test_cat)\n",
    "test_mat = hstack((test_cat, test_text))\n",
    "test_mat = csr_matrix(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a1ba3804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107241, 23085)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6ebdf",
   "metadata": {},
   "source": [
    "### Creating Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3584d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(test_mat)\n",
    "pred = pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "45333104",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "pred_df['post_id'] = test_df['post_id']\n",
    "pred_df['predictions'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0affba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c16685db-c7b2-403e-b56d-4a745d7e4686</td>\n",
       "      <td>0.983742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e65f2de9-acd2-4f03-9395-24f89e1fed32</td>\n",
       "      <td>0.734644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdf973fe-0b45-49d5-b5d6-bbca65c87adc</td>\n",
       "      <td>0.057156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e29d3726-6f7e-42f2-9684-26f1cd3405f8</td>\n",
       "      <td>0.992446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37fb59d9-be82-4985-84ed-9132732b2144</td>\n",
       "      <td>0.068135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                post_id  predictions\n",
       "0  c16685db-c7b2-403e-b56d-4a745d7e4686     0.983742\n",
       "1  e65f2de9-acd2-4f03-9395-24f89e1fed32     0.734644\n",
       "2  cdf973fe-0b45-49d5-b5d6-bbca65c87adc     0.057156\n",
       "3  e29d3726-6f7e-42f2-9684-26f1cd3405f8     0.992446\n",
       "4  37fb59d9-be82-4985-84ed-9132732b2144     0.068135"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "65e6fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.4",
   "language": "python",
   "name": "3.9.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
